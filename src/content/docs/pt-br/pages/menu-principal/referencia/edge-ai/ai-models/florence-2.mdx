---
title: Florence-2 Large
description: >-
  Florence 2 Large é um modelo fundacional de visão avançado que utiliza uma abordagem baseada em prompts e um conjunto de dados massivo para se destacar em diversas tarefas de visão e linguagem visual.
meta_tags: 'edge ai, ai models, inteligência artificial, edge computing'
namespace: docs_edge_ai_models_florence_2
permalink: /documentacao/produtos/ai/edge-ai/modelos/florence-2/
---

**Florence 2** é um modelo fundacional de visão avançado que utiliza uma abordagem baseada em prompts e um conjunto de dados massivo para se destacar em diversas tarefas de visão e linguagem visual.

## Detalhes do modelo

| Categoria | Detalhes |
|----------|---------|
| **Nome do modelo** | Florence 2 |
| **Versão** | Large |
| **Categoria do modelo** | VLM |
| **Tamanho** | 0.77B parâmetros |
| **Modelo HuggingFace** | [microsoft/Florence-2-large](https://huggingface.co/microsoft/Florence-2-large) |
| **Endpoint Compatível com a OpenAI** | [Chat Completions](https://platform.openai.com/docs/api-reference/chat/create) |
| **Licença** | [MIT](https://huggingface.co/microsoft/Florence-2-large/resolve/main/LICENSE) |

## Capacidades 

| Recurso | Status |
|---------|--------|
| Tool Calling | ❌ |
| Suporte a longo prazo da Azion (LTS) | ❌ |
| Tamanho do Contexto | 4096 |
| Suporta LoRA | ❌ |
| Dados de entrada | TEXTO + IMAGEM |

## Uso 


Florence utiliza tags de acordo com cada tarefa que irá realizar. Abaixo estão todas as tags com suas tarefas correspondentes.

### Tarefas sem entrada adicional:

- Imagem inteira para linguagem natural:

| Tag | Descrição |
|------|-------------|
| `<CAPTION>` | Legenda breve ao nível da imagem |
| `<DETAILED_CAPTION>` | Legenda detalhada ao nível da imagem |
| `<MORE_DETAILED_CAPTION>` | Legenda muito detalhada ao nível da imagem |

- Imagem inteira ou região para texto:

| Tag | Descrição |
|------|-------------|
| `<OCR>` | OCR para imagem inteira |
| `<OCR_WITH_REGION>` | OCR para imagem inteira, com caixas delimitadoras para itens de texto individuais |

- Imagem inteira para regiões e categorias ou labels de linguagem natural:

| Tag | Descrição |
|------|-------------|
| `<REGION_PROPOSAL>` | Propõe caixas delimitadoras para objetos salientes (sem rótulos) |
| `<OD>` | Identifica objetos via caixas delimitadoras e fornece rótulos categóricos |
| `<DENSE_REGION_CAPTION>` | Identifica objetos via caixas delimitadoras e fornece labels de linguagem natural |

#### Tarefas com entrada adicional de região
    
- Região para segmentação:

| Tag | Descrição |
|------|-------------|
| `<REGION_TO_SEGMENTATION>` | Segmenta objeto saliente em uma dada região |

- Região para texto:
    
| Tag | Descrição |
|------|-------------|
| `<REGION_TO_CATEGORY>` | obtém classificação do objeto para caixa delimitadora |
| `<REGION_TO_DESCRIPTION>` | obtém descrição de linguagem natural para os conteúdos da caixa delimitadora |

#### Tarefas com entrada de linguagem natural

- Linguagem natural para regiões (um para muitos):

| Tag | Descrição |
|------|-------------|
| `<CAPTION_TO_PHRASE_GROUNDING>` | Dada uma legenda, fornece caixas delimitadoras para ancorar visualmente frases na legenda |

- Linguagem natural para região (um para um):
    
| Tag | Descrição |
|------|-------------|
| `<OPEN_VOCABULARY_DETECTION>` | Detecta caixa delimitadora para objetos e texto OCR |

- Linguagem natural para segmento (um para um):

| Tag | Descrição |
|------|-------------|
| `<REFERRING_EXPRESSION_SEGMENTATION>` | Segmentação de Expressão Referente - dada uma descrição em linguagem natural, identifica a região segmentada correspondentee |

Assim deve ser uma requisição usando as tags do Florence:

```bash
curl -X POST http://endpoint-url/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
   "model": "microsoft/Florence-2-large",
   "messages":  [
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://images.unsplash.com/photo-1543373014-cfe4f4bc1cdf?q=80&w=3148&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
                    }
                },
                {"type": "text", "text": "<DETAILED_CAPTION>"}
            ]
        }
    ]
}'
```

### Executando com Edge Functions:

Este é um exemplo de como executar este modelo com Edge Functions:

```ts
const modelResponse = await Azion.AI.run("microsoft-florence-2-large", {
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": {
            "url": "https://images.unsplash.com/photo-1543373014-cfe4f4bc1cdf?q=80&w=3148&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
          }
        },
        {
          "type": "text",
          "text": "<DETAILED_CAPTION>"
        }
      ]
    }
  ]
})
```

## Schema JSON

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [
    "messages"
  ],
  "properties": {
    "messages": {
      "type": "array",
      "items": {
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "const": "user"
          },
          "content": {
            "type": "array",
            "maxItems": 2,
            "items": {
              "oneOf": [
                {
                  "type": "object",
                  "required": [
                    "type",
                    "image_url"
                  ],
                  "properties": {
                    "type": {
                      "const": "image_url"
                    },
                    "image_url": {
                      "type": "object",
                      "required": [
                        "url"
                      ],
                      "properties": {
                        "url": {
                          "type": "string",
                          "format": "uri"
                        }
                      }
                    }
                  }
                },
                {
                  "type": "object",
                  "required": [
                    "type",
                    "text"
                  ],
                  "properties": {
                    "type": {
                      "const": "text"
                    },
                    "text": {
                      "type": "string",
                      "enum": [
                        "<OCR>",
                        "<CAPTION>",
                        "<DETAILED_CAPTION>",
                        "<MORE_DETAILED_CAPTION>",
                        "<OCR_WITH_REGION>",
                        "<REGION_PROPOSAL>",
                        "<OD>",
                        "<DENSE_REGION_CAPTION>"
                      ]
                    }
                  }
                },
                {
                  "type": "object",
                  "required": [
                    "type",
                    "text"
                  ],
                  "properties": {
                    "type": {
                      "const": "text"
                    },
                    "text": {
                      "type": "string",
                      "allOf": [
                        {
                          "not": {
                            "pattern": "<OCR>|<CAPTION>|<DETAILED_CAPTION>|<MORE_DETAILED_CAPTION>|<OCR_WITH_REGION>|<REGION_PROPOSAL>|<OD>|<DENSE_REGION_CAPTION>"
                          }
                        },
                        {
                          "pattern": "<REGION_TO_SEGMENTATION>|<REGION_TO_CATEGORY>|<REGION_TO_DESCRIPTION>|<PHRASE_GROUNDING>|<OPEN_VOCABULARY_DETECTION>|<REFERRING_EXPRESSION_SEGMENTATION>"
                        }
                      ]
                    }
                  }
                }
              ]
            }
          }
        }
      }
    }
  }
}
```