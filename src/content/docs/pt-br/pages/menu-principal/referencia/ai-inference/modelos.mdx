---
title: Modelos do AI Inference da Azion
description: >-
  O AI Inference oferece uma variedade de modelos otimizados para o edge para vários domínios de AI, garantindo implementação e desempenho eficientes.
meta_tags: 'ai inference, modelos ai, inteligência artificial, edge computing'
namespace: docs_edge_ai_models
permalink: /documentacao/produtos/ai/ai-inference/modelos/
menu_namespace: AIInferenceMenu
---

import LinkButton from 'azion-webkit/linkbutton';

Os modelos otimizados para o edge da Azion abrangem múltiplos domínios de AI, incluindo geração de texto, análise de imagem, embeddings e mais. Cada modelo é projetado para equilibrar o desempenho e a eficiência de recursos para implementação no edge.

Esta página fornece uma lista de modelos disponíveis para uso no **AI Inference**. Para saber mais, visite a página de [referência do AI Inference](/pt-br/documentacao/produtos/ai/ai-inference/).

## Modelos disponíveis

### Mistral 3 Small (24B AWQ)

Este é um modelo de linguagem que, embora compacto, oferece capacidades comparáveis às de modelos maiores. É ideal para agentes conversacionais, function calling, ajuste fino e inferência local com dados sensíveis.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/mistral-3-small/" label="Ver detalhes" severity="secondary" />

### BAAI/bge-reranker-v2-m3

Um modelo de reranking leve com fortes capacidades multilíngues. Ele é fácil de implementar, com inferência rápida.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/baai-bge-reranker-v2-m3/" label="Ver detalhes" severity="secondary" />

### InternVL3

InternVL3 é um Multimodal Large Language Model avançado (MLLM) com capacidades para abranger tool calling, agentes GUI, análise de imagem industrial, percepção de visão 3D e mais.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/internvl3/" label="Ver detalhes" severity="secondary" />

### Qwen2.5 VL AWQ 3B

Um Vision Languagem Model (VLM) que oferece capacidades avançadas como análise visual, raciocínio de agente, compreensão de vídeos longos, localização visual e geração de saída estruturada. Suporta 3 bilhões de parâmetros.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/qwen-2-5-vl-3b/" label="Ver detalhes" severity="secondary" />

### Qwen2.5 VL AWQ 7B

Um Vision Languagem Model (VLM) que suporta 7 bilhões de parâmetros, oferecendo capacidades avançadas como análise visual, raciocínio de agente, compreensão de vídeo longo, localização visual e geração de saída estruturada.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/qwen-2-5-vl-7b/" label="Ver detalhes" severity="secondary" />

### Qwen3 30B A3B Instruct 2507 FP8

Um modelo de linguagem causal FP8 ajustado por instruções com 30 bilhões de parâmetros para geração de texto de longo contexto (256K) e raciocínio, suportando chat/QA, sumarização, tarefas multilíngues, resolução de problemas de matemática/ciência, codificação e fluxos de trabalho aumentados por ferramentas.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/qwen3-30ba3b/" label="Ver detalhes" severity="secondary" />

### Qwen3 Embedding 4B

Um modelo de embedding multilíngue com 4 bilhões de parâmetros (36 camadas, 32K de contexto) que gera vetores de 2560 dimensões para recuperação de texto/código, classificação, agrupamento e mineração de bitexto. Ele suporta embeddings condicionados por instrução e é otimizado para aprendizado de representação eficiente e multilíngue.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/qwen3-embedding-4b/" label="Ver detalhes" severity="secondary" />

### Nanonets-OCR-s

Um modelo OCR que converte imagens de documentos em markdown estruturado, preservando o layout (títulos, listas, tabelas) e tags básicas. A saída é fácil de analisar e alimentar em pipelines de LLM.

<LinkButton link="/pt-br/documentacao/produtos/ai/ai-inference/modelos/nanonets-ocr-s/" label="Ver detalhes" severity="secondary" />
