---
title: Azion AI Inference Models
description: >-
  Edge AI offers a diverse range of edge-optimized models for various AI domains, ensuring efficient deployment and performance.
meta_tags: 'ai inference, ai models, artificial intelligence, edge computing'
namespace: docs_edge_ai_models
permalink: /documentation/products/ai/ai-inference/models/
---

import LinkButton from 'azion-webkit/linkbutton';

Azion's edge-optimized models span multiple AI domains including text generation, image analysis, embeddings, and more. Each model is designed to balance performance and resource efficiency for edge deployment.

This page provides a list of models available for use with **Edge AI**. To learn more about it, visit the [Edge AI Reference](/en/documentation/products/ai/ai-inference/).

## Available Models

### Mistral 3 Small (24B AWQ)

This is a language model that delivers capabilities comparable to larger models while being compact. It is ideal for conversational agents, function calling, fine-tuning, and local inference with sensitive data.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/mistral-3-small/" label="View details" severity="secondary" />

### BAAI/bge-reranker-v2-m3

A lightweight reranker model with strong multilingual capabilities. It offers multilingual support and it's easy to deploy, with fast inference.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/baai-bge-reranker-v2-m3/" label="View details" severity="secondary" />

### InternVL3

InternVL3 is an advanced multimodal large language model with capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/internvl3/" label="View details" severity="secondary" />

### Qwen2.5 VL AWQ 3B

A Vision Language Model (VLM) that offers advanced capabilities such as visual analysis, agentic reasoning, long video comprehension, visual localization, and structured output generation.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/qwen-2-5-vl-3b/" label="View details" severity="secondary" />

### Qwen2.5 VL AWQ 7B

An instruction-tuned 30B-parameter FP8 causal language model for long-context (256K) text generation and reasoning, supporting chat/QA, summarization, multilingual tasks, math/science problem solving, coding, and tool-augmented workflows.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/qwen-2-5-vl-7b/" label="View details" severity="secondary" />

### Qwen3 30B A3B Instruct 2507 FP8

An instruction-tuned 30B-parameter FP8 causal language model for long-context (256K) text generation and reasoning, supporting chat/QA, summarization, multilingual tasks, math/science problem solving, coding, and tool-augmented workflows.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/qwen3-30ba3b/" label="View details" severity="secondary" />

### Qwen3 Embedding 4B

A 4B-parameter multilingual embedding model (36 layers, 32K context) that outputs 2560â€‘dim vectors for text/code retrieval, classification, clustering, and bitext mining. It supports instruction-conditioned embeddings and is optimized for efficient, cross-lingual representation learning.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/qwen3-embedding-4b/ " label="View details" severity="secondary" />

### Nanonets-OCR-s

An OCR model that converts document images to structured Markdown, preserving layout (headings, lists, tables) and basic tags. The output is easy to parse and feed into LLM pipelines.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/nanonets-ocr-s/" label="View details" severity="secondary" />

### GPT-OSS 20B

An OpenAI model with 20 billion parameters, designed for text generation, conversation, and various natural language processing tasks. This open-source model provides robust performance for a wide range of applications with tool calling capabilities and 131k token context length.

<LinkButton link="/en/documentation/products/ai/ai-inference/models/gpt-oss-20b/" label="View details" severity="secondary" />
