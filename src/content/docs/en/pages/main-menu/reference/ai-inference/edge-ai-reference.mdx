---
title: AI Inference
description: >-
  AI Inference enables you to run AI models directly on Azion’s highly distributed infrastructure.
meta_tags: 'ai inference, artificial intelligence, edge computing, ai assistant, ai agente'
namespace: docs_edge_ai_reference
permalink: /documentation/products/ai/ai-inference/
menu_namespace: AIInferenceMenu

---

import LinkButton from 'azion-webkit/linkbutton';

**AI Inference** enables you to run AI models directly on Azion’s highly distributed infrastructure.

With Azion AI Inference, you can integrate AI capabilities into your applications, leveraging tools like **Functions**, **Applications**, **Vector Search**, and the Azion API to create scalable, secure, and efficient solutions.

Get started by deploying the AI Inference Starter Kit Template:

<LinkButton
    label="Deploy"
    link="https://console.azion.com/create/azion/starter-kit-edge-ai"
    icon="ai ai-azion"  
    icon-pos="left"
  />

---

## Features

### OpenAI-Compatible API

Connect applications using Azion’s OpenAI-compatible endpoint format.

### Run Edge optimized models

- Run AI models on Azion’s globally distributed edge to minimize latency and enable real-time inference.
- Access a curated catalog of open-source models, ready to run on Azion Runtime and optimized for distributed deployment with low resource footprints.
- Native inference support for large language models (LLMs) and vision-language models (VLMs).

<LinkButton link="/en/documentation/products/ai/ai-inference/models/" label="See Available Models" severity="secondary" />

### Fine-Tune Models with LoRA

AI Inference allows you to fine-tune, train, and specialize models your own data and parameters. This capability enables you to optimize models for specific tasks, ensuring they are both efficient and accurate for your business needs.

---

### Examples of what you can build with AI Inference

- **AI Assistants**: Build and deploy AI assistants that serve thousands of users simultaneously with low latency, delivering real-time support, dynamic FAQs, and customer assistance without cloud overload.

- **AI Agents**: Build AI agents that automate multi‑step workflows, collapse days of manual effort into minutes, and free teams for higher‑value work—boosting productivity across operations. 

- **Automate Threat Detection and Takedown with AI**: Combine LLMs and vision-language models (VLMs) to monitor digital assets, spot phishing/abuse patterns in text and imagery, and automate threat classification and takedown across distributed environments. 

## Integration with SQL Database

Integrate your application with **SQL Database** to enable [vector search](/en/documentation/products/store/sql-database/vector-search/) capabilities, allowing for semantic queries and hybrid search. This integration enhances AI-powered applications by providing precise, contextually relevant results and supporting efficient Retrieval-Augmented Generation (RAG) implementations.

## Limits

These are the **default limits**:

| Scope | Limit | 
| ----- | ----- | 
| Requests per minute | 300  |

---

## Related products

- [Applications](/en/documentation/products/build/applications/): build applications that run directly on Azion's distributed infrastructure, delivering exceptional performance and customization options.
- [Functions](/en/documentation/products/build/applications/functions/): execute code closer to end users, enhancing performance and enabling custom logic for handling requests and responses.
- [SQL Database](/en/documentation/products/store/sql-database/): an edge-native SQL solution designed for serverless applications, providing data storage and querying capabilities at the edge. Also enables [Vector Search](/en/documentation/products/store/sql-database/vector-search/) for performing semantic search and AI-powered recommendations through vector embedding.

