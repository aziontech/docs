---
title: How edge computing works
description: Edge computing emerged as a topological architecture where the proximity of computing and processing power is closer to the user.
meta_tags: edge computing, serverless, Azion Edge Network
namespace: documentation_edge_foundations_how_edge_computing_works
permalink: /documentation/products/edge-foundations/how-edge-computing-works/
---
import Button from '~/components/Button.astro';

## Historical context and evolution

To better understand the rise of edge computing and how it works, it's helpful to review the historical context around the different stages of computing.

[IMG Historical context and evolution: in-progress]

The exponential growth of online data has forced the technology market to look for new solutions that allow serving it, especially related to the storage and processing of all this data in a faster and safer way. From centralized mainframes to distributed systems, each stage has brought significant advancements in how applications are built and run. 

### 1900s

The Internet boom sparked the first massive increase in the use of data centers, with applications hosted on "bare-metal servers". In this stage, specialized facilities, managed by external providers, offered infrastructure for businesses to deploy their servers for the colocation of services.

In these early days, applications were typically built as monolithic systems, being large, self-contained entities where all components were tightly coupled together.

With the rise of networking and the Internet, applications were divided into two main components: the client, which ran on the user's device and handled the user interface, and the server, which performed the application's core processing and data management. It enabled distributed computing and allowed for scalability and remote access.

### Early 2000s

This stage is defined by the introduction of hosting services and the emergence of virtualization technology.

It brought web applications, built using web technologies such as HTML, CSS, and JavaScript. Web browsers acted as the clients, and the server hosted the application logic, making it easier to develop and deploy software across different platforms and devices.

### Mid-2000s

The advent of Software as a Service (SaaS) was the biggest novelty. In this new model, businesses access software applications over the Internet, eliminating the need to install and manage these applications on their own hardware.

As applications became more complex, the focus shifted to modularization and reusability. Service-Oriented Architecture (SOA) emerged as an approach to building applications by encapsulating functionality into services that could be independently developed, deployed, and consumed. These services communicate with each other over networks using standard protocols like SOAP or REST.

### Late 2000s and early 2010s

Cloud computing took center stage, allowing businesses to scale up or down as needed, paying only for the resources they use. Content Delivery Networks (CDNs) also gained prominence, initially focusing on caching content, and enhancing the speed and reliability of content delivery.

By using cloud computing, applications could be developed, deployed, and scaled using virtualized resources on-demand.

### Mid-2010s

The introduction of containerization happened at this moment, wrapping applications and their dependencies into self-contained, executable packages.

Containerization technologies gained popularity, allowing applications to be packaged into lightweight, portable containers. Container orchestration tools like Kubernetes enabled efficient deployment, scaling, and management of containerized applications across distributed environments.

### Late-2010s

Serverless computing abstracts away the infrastructure management aspect of application development. ​​Besides, microservices architecture appears as an evolution of SOA, emphasizing even finer-grained services.

Through a serverless approach, developers focus solely on writing code or functions without worrying about servers or infrastructure. The providers handle the scaling, execution, and billing based on the actual usage of the application.

While with microservices, applications were built as a collection of loosely coupled, independently deployable services. Each service focuses on a specific business capability and can be developed, deployed, and scaled independently.

<iframe
width="560"
height="315"
src="https://www.youtube.com/embed/veQ_-tlzpic?si=S5kHrjQNUGQYPRHe"
loading="lazy"
title="From Past to Present: The Evolutionary Journey of Edge Computing"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
allowfullscreen></iframe>

---

## How edge computing works

Despite the advances they brought at the time, centralized cloud infrastructure and data centers strain network bandwidth and fail to meet the demands for low-latency applications, as well as struggle to deliver acceptable transfer rates and response times, which are crucial for many modern applications and use cases.

In response to these challenges, **edge computing** emerged as a topological architecture where the proximity of computing and processing power is closer to the user, in the so-called *last mile*. 

There are some key principles to understand the edge computing architecture:

- Servers are physically closer to the client and located in front of the cloud infrastructure so that data doesn’t have to travel great distances to respond to requests.
- This process can be completed faster and more efficiently because requests are resolved at the edge, with less data traveling, and not in the origin's infrastructure or cloud.
- It's inherently decentralized and geographically distributed, which means that workloads can be spread across multiple nodes (servers) and load-balanced, being scalable and fault-tolerant.

[IMG edge architecture: in-progress]

1. The outermost layer in edge architecture includes **end-user devices**, **gadgets**, and **sensors**. These devices gather data from the physical environment and enable real-time processing and analysis at the edge.
2. These devices are typically connected to **local or private networks**, with latency lower than 5ms.
3. **Edge nodes** are the computing devices located at the edge of the network, including routers, switches, gateways, IoT devices, and other edge server configurations. The nodes are responsible for processing and storing data locally, with reduced latency (up to 30ms) and low network congestion. Additionally, they can enable seamless integration with cloud-based services. These nodes can run various applications and services, such as real-time analytics, content delivery, and other edge-based functionalities, bringing computational capabilities closer to the network edge.
4. The **centralized cloud and data centers** work as the origin, also providing remote management and orchestration, large data aggregation and storage, complex analytics, and global connectivity.

To sum up, edge computing allows efficient data processing and analysis at the network edge, enabling real-time insights and actions. By leveraging edge devices, nodes, and servers, organizations can achieve faster response times, reduce latency, and improve performance, making edge computing a vital component in the evolving landscape of computing architectures.

<iframe
width="560"
height="315"
src="https://www.youtube.com/embed/DWHdCaozp9Q?si=u-LRbU1IIHI42NST"
loading="lazy"
title="Exploring Edge Computing: A Comprehensive Guide to Its Components"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
allowfullscreen></iframe>

## Edge vs. legacy architectures

Serverless computing is often used synonymously with edge computing. However, they differ in certain ways. Serverless is a model that allows developers to build and run applications without having to manage servers and this new level of abstraction has made the edge computing market viable.

Additionally, it's important to note that the serverless approach is still part of the traditional centralized infrastructure, being originated and operating in cloud providers. It may not meet modern applications' demands as effectively as edge computing solutions.

Edge computing is also frequently compared and related to cloud computing and other legacy architectures, but they exhibit fundamental differences in their approach and functionality. While legacy architectures rely on centralized data centers located at a distance from end users and devices, edge computing decentralizes these resources, reducing latency significantly and enabling real-time or near-real-time processing.

In general, those architectures excel at providing vast storage and computing resources, ideal for data-intensive tasks, while edge computing shines when low latency, privacy, and immediate local decision-making are key.

<iframe
width="560"
height="315"
src="https://www.youtube.com/embed/d0z1oIPI8WY?si=5SiLfkF5Uizt0uBZ"
loading="lazy"
title="Edge Computing, Cloud Computing, and Legacy Architectures: An In-depth Comparison"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
allowfullscreen></iframe>

Overall, cloud computing and edge computing paradigms often serve as integral components of modern computing ecosystems and complement each other, allowing organizations to create hybrid architectures, delivering a more versatile and efficient computing environment for various applications and industries.

<Button href="Learning material" text="Go to the edge and hybrid-cloud workloads case" variant="secondary"> 

</Button>


