---
title: How to configure Data Stream main settings
description: Find out how to configure the main settings of a stream.
meta_tags: Data Stream, how to, use, stream, event, logs, observe, observability
namespace: documentation_using_dts
permalink: /documentation/products/guides/use-data-stream/
menu_namespace: observeMenu
---

import Tabs from '~/components/tabs/Tabs'
import JourneyAPI from '~/includes/snippets/JourneyAPI/en/snippet.mdx'

:::caution[important]
Azion has two user interfaces: Real-Time Manager and Console, which is in *Preview* stage. Currently, Console is only available for Developer plans and new accounts. Follow the steps according to the user interface you're using.
:::

While creating or editing a stream, there are a few specific main configurations you can define and modify.

To find more detailed information on the product and each configuration, see the [reference documentation](/en/documentation/products/observe/data-stream/).

---

<Tabs>
    <Fragment slot="tab.console">Console</Fragment>
    <Fragment slot="tab.rtm">Real-Time Manager</Fragment>
    <Fragment slot="tab.api">API</Fragment>

<Fragment slot="panel.console">

In this section, you’ll modify the main settings of your stream: name, data source, template, domains, and destination via [Azion Console](https://console.azion.com/).

1. [Access Azion Console](/en/documentation/products/guides/how-to-access-rtm/) > **Data Stream**.
2. From the list, select the stream you want to edit or click the **+ Stream** button.
3. Give your stream a unique and easy-to-remember name.
4. On the **Source** dropdown menu, select the one you want to use: **Activity History**, **Edge Applications**, **Edge Functions**, or **WAF Events**.
    - For **Edge Functions** and **WAF Events**, you must be [subscribed to the products](/en/documentation/products/data-stream/first-steps/).
5. On the **Template** dropdown menu, select the one you want to use.
    - You can modify the presented JSON in the **Data Set** code box, adding the variables you want to use in your logs' analysis. See more on [How to create a custom template on Data Stream](/en/documentation/products/guides/data-stream-custom-template/).
6. On **Domains** > **Options**, select between ****All Curent and Future Domains** or **Filter Domains**.
    - See more about each option on [How to associate domains on Data Stream](/en/documentation/products/guides/data-stream-associate-domains/).
7. Under **Destination**, select a **Connector** on the dropdown menu: **Standard HTTP/HTTPS POST**, **Apache Kafka**, **Simples Storage Service (S3)**, **Google BigQuery**, **Elasticsearch**, **Splunk**, **AWS Kinesis Data Firehose**, **Datadog**, **IBM QRadar**, **Azure Monitor**, or **Azure Blob Storage**.
    - You'll see different fields depending on the endpoint type you choose. Find more information on each of them on the [Setting an endpoint page](/en/documentation/products/observe/data-stream/#endpoints).
8. Click the **Save** button.

</Fragment>

<Fragment slot="panel.rtm">

In this section, you’ll modify the main settings of your stream: name, data source, template, domains, and destination via [Real-Time Manager](https://manager.azion.com/).

1. [Access Real-Time Manager](https://manager.azion.com/) > **Data Stream**.
2. From the list, select the stream you want to edit or click the **Add Streaming** button.
3. Give your stream a unique and easy-to-remember name.
4. On the **Data Source** dropdown menu, select the one you want to use: **Activity History**, **Edge Applications**, **Edge Functions**, or **WAF Events**.
    - For **Edge Functions** and **WAF Events**, you must be [subscribed to the products](/en/documentation/products/data-stream/first-steps/).
5. On the **Template** dropdown menu, select the one you want to use: a pre-set template according to your chosen data source or a **Custom Template**.
    - If you choose **Custom Template**, add the variables you want to use in your logs' analysis in the **Data Set** code box. See more on [How to create a custom template on Data Stream](/en/documentation/products/guides/data-stream-custom-template/).
6. On **Options**, select between **Filter Domains** or **All Domains**.
    - See more about each option on [How to associate domains on Data Stream](/en/documentation/products/guides/data-stream-associate-domains/).
7. Under **Destination**, select an **Endpoint Type** on the dropdown menu: **Standard HTTP/HTTPS POST**, **Apache Kafka**, **Simples Storage Service (S3)**, **Google BigQuery**, **Elasticsearch**, **Splunk**, **AWS Kinesis Data Firehose**, **Datadog**, **IBM QRadar**, **Azure Monitor**, or **Azure Blob Storage**.
    - You'll see different fields depending on the endpoint type you choose. Find more information on each of them on the [Setting an endpoint page](/en/documentation/products/observe/data-stream/#endpoints).
8. Click the **Save** button.

</Fragment>

<Fragment slot="panel.api">

For this section, you'll be modifying an existing stream with an Elasticsearch connector via API. To create a new one, use the [Data Stream POST method](https://api.azion.com/#b9aac0c7-173a-462b-87f6-a18d6558d3e5).

Check the [Data Stream Properties](https://api.azion.com/#b9aac0c7-173a-462b-87f6-a18d6558d3e5) table to see all available properties and their accepted values.

1. Run the following `GET` request in your terminal, replacing `[TOKEN VALUE]` with your [personal token](/en/documentation/products/guides/personal-tokens/) to retrieve your `<data_streaming_id>`:

```bash
curl --location 'https://api.azionapi.net/data_streaming/streamings' \
--header 'Accept: application/json; version=3' \
--header 'Authorization: Token [TOKEN VALUE]'
```

2. You'll receive a response with all your existing streams. Copy the value of the `<id>` that you want to configure.
3. Run a `PATCH` request to modify the stream as follows:

```bash
curl --location --request PATCH 'https://api.azionapi.net/data_streaming/streamings/<data_streaming_id>' \
--header 'Accept: application/json; version=3' \
--header 'Authorization: Token [TOKEN VALUE]' \
--header 'Content-Type: application/json' \
--data '{
	"name": "My Elasticsearch connector",
    "template_id": 2,
    "domain_ids": [1656613172],
    "data_source": "http",
    "endpoint": {
        "endpoint_type": "elasticsearch",
        "url": "http://elasticsearch-domain.com",
        "api_key": "VuaCfGcBCdbkQm-e5aOx:ui2lp2axTNmsyakw9tvNnw"
    },
    "all_domains": false
}'
```

| Key | Description |
| --- | --- |
| `name` | Name of the stream |
| `template_id` | Identifier for the template being used |
| `domain_ids` | Array value of the domain's identifiers (integers) you want to associate with the stream |
| `data_source` | Data source from which you want to stream your data |
| `endpoint` | Endpoint to which you want to stream your data |
| `all_domains` | Used to associate all current and future domains in your account to the stream |

4. You'll receive a response similar to this:

```json
{
  "results": {
    "id": 1560,
    "name": "My Elasticsearch connector",
    "template_id": 2,
    "data_source": "http",
    "active": true,
    "endpoint": {
      "endpoint_type": "elasticsearch",
      "url": "http://elasticsearch-domain.com",
      "api_key": "VuaCfGcBCdbkQm-e5aOx:ui2lp2axTNmsyakw9tvNnw"
    },
    "all_domains": false
  },
  "schema_version": 3
}
```

Wait a few minutes for the changes to propagate and your stream will be updated.

    <JourneyAPI />

</Fragment>

</Tabs>

Watch a video tutorial on how to use Data Stream on Azion's YouTube channel:

<iframe
   src="https://www.youtube.com/embed/CT2VyftnOZs"
   loading="lazy"
   width="600"
   height="400"
   title="How to Use Data Stream"
   frameborder="0"
   allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
   allowfullscreen></iframe>

<br /><br />
---

import ContributorList from '~/components/ContributorList.astro'

**Contributors** <ContributorList>Contributor</ContributorList>
