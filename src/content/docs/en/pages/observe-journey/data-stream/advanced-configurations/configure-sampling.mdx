---
title: How to configure sampling on Data Stream
description: >-
  Configure the Sampling feature to filter the percentage of data you'll be
  streaming.
meta_tags: 'Data Stream, observe, observability, logs, sampling'
namespace: docs_data_streaming_sampling
permalink: /documentation/products/guides/observe/configure-sampling/
menu_namespace: observeMenu
---

import Tabs from '~/components/tabs/Tabs'
import JourneyAPI from '~/includes/snippets/JourneyAPI/en/snippet.mdx'


When you [configure a stream](/en/documentation/products/guides/use-data-stream/) and choose to associate all of your domains, you can configure the **Sampling** option to filter the percentage of data you'll be streaming. It's a viable option to reduce the costs of data collection and analysis.

:::caution[warning]
To enable Sampling on your account, you must contact the [sales team](https://www.azion.com/en/contact-sales/) and request the feature.

Once you enable the Sampling feature, you can only have one active stream. If you disable it, you'll be able to create more streams again.
:::

---

<Tabs client:visible>
    <Fragment slot="tab.console">Console</Fragment>
    <Fragment slot="tab.api">API</Fragment>

<Fragment slot="panel.console">

1. [Access Azion Console](/en/documentation/products/guides/how-to-access-azion-console/) > **Data Stream**.
2. To configure the stream, follow the steps in [How to configure Data Stream main settings](/en/documentation/products/guides/use-data-stream/).
3. On **Worloads** > **Options**, choose **All Curent and Future Domains**.
4. On **Sampling (%)**, add the value of the percentage of data you want to stream, from `0` to `100`. Example: `60`.
    - Data Stream will collect data randomly according to the percentage you choose.
5. Finish configuring the **Destination** section.
6. Click the **Save** button.

</Fragment>


<Fragment slot="panel.api">

For this section, you'll be creating a stream with an Apache Kafka connector via API. See other connector options in the [Data Stream Endpoints](https://api.azion.com/#04257075-3691-4b5f-b22b-22a5b6653f3f) table.

1. Run the following `POST` request in your terminal, replacing `[TOKEN VALUE]` with your [personal token](/en/documentation/products/guides/personal-tokens/):

```bash
curl --request POST \
  --url https://api.azion.com/v4/data_stream/streams \
  --header 'Accept: application/json' \
  --header 'Authorization: [TOKEN VALUE]' \
  --header 'Content-Type: application/json' \
--data '{
    "name": "Kafka Connector",
    "template_id": 2,
    "workloads": [1656613172],
    "data_source": "http",
    "endpoint": {
        "endpoint_type": "kafka",
        "kafka_topic": "mykafka.dts.topic",
        "bootstrap_servers": "infra.my.net:9094,infra.my.net:9094"
    },
    "all_domains": true,
    "sampling_percentage": 60
}'
```

2. You'll receive a response similar to this:

```json
{
  "results": {
    "id": 1594,
    "name": "Kafka Connector",
    "template_id": 2,
    "data_source": "http",
    "active": true,
    "endpoint": {
      "endpoint_type": "kafka",
      "use_tls": false,
      "kafka_topic": "mykafka.dts.topic",
      "bootstrap_servers": "infra.my.net:9094,infra.my.net:9094"
    },
    "all_domains": true,
    "sampling_percentage": 60
  },
  "schema_version": 3
}
```

Wait a few minutes for the changes to propagate and your stream will be updated.

  <JourneyAPI />


</Fragment>

</Tabs>

<br /><br />

