---
title: How to build a simple agent with AI Inference
description: The "+ Create" button accelerates your journey to start building with Azion.
meta_tags: >-
  building, onboarding, create resources, Azion Web Platform, import from
  GitHub
namespace: docs_guides_ai_inference_build_agent
permalink: /documentation/products/guides/ai-inference-agent/
menu_namespace: AIInferenceMenu

---



## Usage

AI Inference can be used in a [Function]

This function receives a POST request to the desired AI model and returns the response.


```javascript
const modelResponse = await Azion.AI.run("Qwen/Qwen3-30B-A3B-Instruct-2507-FP8", {
  "stream": true,
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Name the european capitals"
    }
  ]
})
return modelResponse
```

This example uses the Qwen3 model. You can change the model and the request parameters according to your preferences. Check the [AI models reference](/en/documentation/products/ai/ai-inference/models/) for more information about the available models and how to use them in your application.

